{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddfce08",
   "metadata": {},
   "source": [
    "# 텐서 \n",
    "\n",
    "- 파이토치는 텐서로 시작해서 텐서로 끝남\n",
    "- 텐서를 잘 다룰 수 있어야 신경망에서 데이터 입력과 출력을 제어할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda1774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0659b",
   "metadata": {},
   "source": [
    "## 텐서 생성 및 변환\n",
    "\n",
    "- 텐서는 파이토치의 가장 기본이 되는 데이터 구조\n",
    "- **numpy**의 **다차원배열**과 비슷하며 GPU에서도 연산 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d631ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 텐서 생성\n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu가 있다면\n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4]], device = 'cuda:0') # 0 번째 그래픽 카드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86e5358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype을 이용하여 텐서 생성 \n",
    "torch.tensor([[1, 2],\n",
    "              [3, 4]], dtype = torch.float64) # 0 번째 그래픽 카드 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bec40",
   "metadata": {},
   "source": [
    "### 텐서를 ndarray로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a948fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f015ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ndarray로 변환\n",
    "temp.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ba0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu가 있다면 gpu 상의 텐서를 cpu의 텐서로 변환한 후 ndarray로 변환\n",
    "temp = torch.tensor([[1, 2], [3, 4]], device = \"cuda:0\")\n",
    "temp.to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d531520",
   "metadata": {},
   "source": [
    "## 텐서의 인덱스 조작\n",
    "\n",
    "- 텐서는 넘파이의 다차원배열과 유사하게 동작하기 때문에 배열처럼 인덱스를 바로 지정하거나 슬라이스 등을 사용할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed0f677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치로 1차원 벡터 생성\n",
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27461bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(2.), tensor(7.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스로 접근 \n",
    "temp[0], temp[1], temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e1b89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4., 5.]), tensor([5., 6.]), tensor([2.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이스로 접근\n",
    "temp[2:5], temp[4:-1], temp[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a48d2",
   "metadata": {},
   "source": [
    "## 텐서 연산\n",
    "\n",
    "- 텐서는 넘파이의 다차원배열처럼 다양한 수학 연산이 가능하며, gpu를 사용하면 더 빠르게 연산할 수 있음 \n",
    "- 단, 텐서 간의 타입이 다르면 연산이 불가\n",
    "    - 예) FloatTensor(32비트의 부동 소수점)와 DoubleTensor(64비트의 부동 소수점) 간에 사칙 연산을 수행하면 오류 발생 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc7374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 3인 벡터 생성\n",
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5df4bd",
   "metadata": {},
   "source": [
    "- shape 안 맞추면 에러남 \n",
    "- 데이터의 차원을 잘 다루는게 제일 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ed11b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 길이가 같은 벡터 간 뺄셈 연산\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e9922",
   "metadata": {},
   "source": [
    "## 텐서의 차원조작\n",
    "\n",
    "- 텐서희 차원을 변경하는 명령어\n",
    "    - view : 넘파이의 reshape와 유사\n",
    "    - cat : 다른 길이의 텐서를 하나로 병합\n",
    "    - transpose : 행렬의 전치 또는 차원의 순서 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e24d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 x 2 행렬 생성 ( 2차원텐서를 만듦)\n",
    "temp = torch.tensor([\n",
    "    [1, 2],[3, 4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2365f709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c247fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 2 행렬을 4 x 1로 변경\n",
    "temp.view(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2563834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 2 행렬을 1차원 벡터로 변형  # reshape \n",
    "temp.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51af46",
   "metadata": {},
   "source": [
    "- -1은 다른 차원으로부터 해당 값을 유추하겠다는 뜻 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109f4c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7089600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b34018",
   "metadata": {},
   "source": [
    "# 데이터 로더\n",
    "\n",
    "- torch.utils.data.DataLoader는 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용 \n",
    "\n",
    "- 주의할 점은 미리 데이터를 잘라 놓는 것이 아니라 내부적으로 이터레이터에 포함된 인덱스를 이용하여 배치 크기만큼 데이터를 반환\n",
    "\n",
    "<img src = './image/dataloader.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7890cf",
   "metadata": {},
   "source": [
    "# 파이토치 데이터셋 사용\n",
    "\n",
    "- torchvision은 파이토치에서 제공하는 데이터셋이 모여있는 패키지\n",
    "- 파이토치 데이터셋을 다운로드 받으려면 requests 라이브러리 설치가 필요\n",
    "    - HTTP 요청을 하기 위함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237eef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23b469",
   "metadata": {},
   "source": [
    "### 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a135d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포를 정규화(스케일링)\n",
    "mnist_transform = transforms.Compose([\n",
    "     transforms.ToTensor(), # 받아들인 데이터를 텐서 type으로 바꿈 \n",
    "     transforms.Normalize((0.5, ), (1.0,)) # 그 다음 정규화\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79982430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 15696624.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 28889981.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 20185900.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4485643.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST_DATASET\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(data_path, transform= mnist_transform, train = True, download= True)\n",
    "test_dataset = MNIST(data_path, transform= mnist_transform, train = False, download= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed8b695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d43492",
   "metadata": {},
   "source": [
    "# 모델 정의 \n",
    "\n",
    "- 파이토치에서 모델을 정의하기 위해서는 Module 을 상속한 클래스를 사용 \n",
    "    - layer : 모듈 또는 모듈을 구성하는 한 개의 계층 \n",
    "        - 예) 합성곱층, 선형계층 등 \n",
    "    - module : 한 개 이상의 계층이 모여서 구성된 것, 모듈이 모여 새로운 모듈을 만들 수도 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa437221",
   "metadata": {},
   "source": [
    "- 컨컨풀에서 \n",
    "- 컨 : 레이어\n",
    "- 컨컨풀 모은게 모듈 \n",
    "- 덴스 : 레이어 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00417db5",
   "metadata": {},
   "source": [
    "## nn.Moduel()을 상속하여 정의하는 방법\n",
    "- nn : neural network 인공신경망\n",
    "\n",
    "- 파이토치에서 nn.Module을 상속받는 모델은 기본적으로 \\_\\_init() 과 forward() 함수를 포함 \n",
    "    - \\_\\_init() 에서는 모델에서 사용될 모듈, 활성화 함수 등을 정의 \n",
    "    - forward() 함수 에서는 모델에서 실행되어야 하는 연산을 정의 \n",
    "    \n",
    "- nn.Sequential 을 사용하면 \\_\\_init() 에서 사용할 네트워크 모델들을 정의해 줄 뿐만 아니라 forward() 함수에서 모델에서 실행되어야 할 계산을 좀더 가독성이 뛰어나게 코드로 작성할 수 있음\n",
    "- 또한, Sequential 객체에는 그 안에 포함된 각 모듈을 순차적으로 실행해 줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3b21d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93232b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # super : nn.Module 클래스 로 추가 기능을 넣음 \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 5),\n",
    "            nn.ReLU(inplace = True), # inplace = True 파괴적인 연산 \n",
    "            # input으로 돌아온 값 자체를 수정, 메모리 효율이 좋아지지만 input 값이 사라짐 \n",
    "            nn.MaxPool2d(2)) \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 30, kernel_size = 5),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        # Linear 전결합층 \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features = 750, out_features = 10, bias = True), # bias = True y 절편 쓰냐 안 쓰냐\n",
    "            nn.ReLU(inplace = True)) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.shape[0], -1) # reshape : flatten \n",
    "        x = self.layer3(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1faf23",
   "metadata": {},
   "source": [
    "- init 생성자 \n",
    "- self.layer : 객체 layer 이름으로 Sequential 순차적으로 실행되는 계층 모듈을 만들어줌\n",
    "    - 2차원 convolution 을 만듦 \n",
    "    - 나가는 채널 : 64(유닛이 64), 활성화 함수 : relu, inplace = True : 원본 데이터에 파괴적인 연산을 할 것임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfbcd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b816ea17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " )]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구성 노드를 반환 \n",
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93230452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLP(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " ),\n",
       " Linear(in_features=750, out_features=10, bias=True),\n",
       " ReLU(inplace=True)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 네트워크에 대한 모든 노드를 반환\n",
    "list(model.modules())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a066338",
   "metadata": {},
   "source": [
    "### 함수로 신경망 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "901eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(in_features = 1, hidden_features = 20, out_features = 1):\n",
    "    hidden = nn.Linear(in_features = in_features, out_features = hidden_features, bias = True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features = hidden_features, out_features = out_features, bias = True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e412ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(in_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_tensor = mlp_model(입력값) -> 모델의 순정파 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d08a0b",
   "metadata": {},
   "source": [
    "# 모델 파라미터 정의\n",
    "\n",
    "- 손실 함수(loss function)\n",
    "    - 학습하는 동안 출력과 실제 값(정답) 사이의 오차를 측정 \n",
    "    - wx + b 를 계산한 값과 실제 값 y의 오차를 구해서 모델의 정확성을 측정 \n",
    "    - 자주 사용되는 손실 함수 \n",
    "        - BCELoss ( Binary CrossEntorpy Loss) : 이진 분류를 위해 사용\n",
    "        - CrossEntropyLoss : 다중 클래스 분류를 위해 사용 \n",
    "        - MSELoss : 회귀 모델에서 사용 \n",
    "        \n",
    "        \n",
    "- 옵티마이저(optimizer)\n",
    "    - 데이터와 손실함수를 바탕으로 모델의 업데이트 방법을 결정\n",
    "    - 옵티마이저의 주요 특성\n",
    "        - optimizer는 step() 메서드를 통해 전달받은 파라미터를 업데이트\n",
    "        - 모델의 파라미터별로 다른 기준을 적용시킬 수 있음 \n",
    "        - torch.optim.Optimizer(params, defaults)는 모든 옵티마이저의 기본이 되는 클래스 \n",
    "        - zero_grad() 메서드는 옵티마이저에 사용된 파라미터들의 기울기를 0으로 초기화 \n",
    "        - toch.optim.lr_scheduler는 에포크에 따라 학습률을 조절할 수 있음 \n",
    "        \n",
    "- 학습률 스케줄러(learning rate scheduler) \n",
    "    - 미리 지정한 횟수의 에포크를 지날 때 마다 학습률을 감소시킴 \n",
    "    - 학습률 스케줄러를 이용하면 학습 초기에는 빠른 학습을 진행하다가 전역 최소점(global minimum) 근처에 다다르면 학습률을 줄여서 최적점을 찾아갈 수 있도록 함 \n",
    "    - 학습률 스케줄러의 종류\n",
    "        - optim.lr_scheduler.LambdaLR : 람다 함수를 이용하여 그 함수의 결과를 학습률로 설정 \n",
    "        - optim.lr_scheduler.StepLR : 특정 단계(step)마다 학습률을 감마 비율만큼 감소\n",
    "        - optim.lr_scheduler.MultiStepLR : StepLR 과 비슷하지만 특정 단계가 아닌 지정된 에포크에만 감마 비율로 감소시킴\n",
    "        - optim.lr_scheduler.ExponentialLR : 에포크마다 이전 학습률에 감마만큼 곱함\n",
    "        - optim.lr_scheduler.CosineAnnealingLR : 학습률을 코사인 함수의 형태처럼 변화시킴, 학습률이 커지기도 작아지기도 함\n",
    "        - optim.lr_scheduler.ReduceLROnPlateau : 학습이 잘되고 있는지 아닌지에 따라 동적으로 학습률을 변화 \n",
    "        \n",
    "\n",
    "- 지표(metrics)\n",
    "    - 훈련과 테스트 단계를 모니터링 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f3c63",
   "metadata": {},
   "source": [
    "## 전역 최소점과 최적점\n",
    "\n",
    "<img src = './image/minimum.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865019af",
   "metadata": {},
   "source": [
    "- local optima : 지역 최소점 (너무 커도 안됨, 변동량이 커져서 전역 최소점으로 될 경향이 있다 \n",
    "- 즉, 배치사이즈가 너무 높거나 learning rate가 너무 낮아  힘을 못 받고 내려올 수 있음\n",
    "\n",
    "- 손실 함수는 실제 값과 예측값 차이를 수치화해주는 함수\n",
    "- 이 오차 값이 클수록 손실 함수의 값이 크고, 오차 값이 작을수록 손실 함수의 값이 작아짐\n",
    "- 손실 함수의 값을 최소화하는 가중치와 바이어스를 찾는 것이 모델 학습의 목표 \n",
    "- 전역 최소점(global minimun)은 오차가 가장 작을 때의 값을 의미하므로 우리가 최종적으로 찾고자 하는 것. 최적점 \n",
    "- 지역 최소점(local minimun)은 전역 최소점을 찾아가는 과정에서 만나는 홀(hole)과 같은 것으로 옵티마이저가 지역 최소점에서 학습을 멈추면 최솟값을 찾는 오차를 찾을 수 없는 문제가 발생 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cfcec",
   "metadata": {},
   "source": [
    "# 모델 훈련 \n",
    "\n",
    "- 모델을 학습시킨다는 것은 y = wx + b 라는 함수에서 w와 b의 적절한 값을 찾는다는 의미\n",
    "- w와 b에 임의의 값을 적용하여 시작하며 오차가 줄어들어 전역 최소점에 이룰 때까지 파라미터(w, b)를 계속 수정\n",
    "- 딥러닝 학습 절차\n",
    "    1. 모델, 손실 함수, 옵티마이저 정의\n",
    "    2. 전방향 학습(입력 -> 출력 계산) , 전방향 = 순전파 \n",
    "    3. loss function손실 함수로 출력과 정답의 차이(오차) 계산\n",
    "    4. 역전파 학습(기울기 계산) gradient \n",
    "    5. 기울기 업데이트 \n",
    "    \n",
    "- 파이토치 학습 절차\n",
    "    1. 모델, 손실 함수, 옵티마이저 정의\n",
    "        - optimizer.zero_grad() : 기울기 초기화\n",
    "            - 파이토치는 기울기 값을 계산하기 위해 loss.backward() 메서드를 사용하는데, 이때 새로운 기울기 값이 이전 기울기 값에 누적하여 계산됨 \n",
    "            - 기울기 누적은 순환 신경망을 구현할 때 효과적이지만 누적 계산이 필요하지 않는 모델에서는 불필요함\n",
    "            - 따라서 기울기 누적 계산이 필요하지 않을 때는 입력값을 모델에 적용하기 전에 미분값이 누적 되지 않게 초기화해야 함 \n",
    "           \n",
    "            \n",
    "    2. output = model(input) : 출력 계산 \n",
    "    3. loss = loss_fn(output, target) : 오차 계산 \n",
    "    4. loss.backward() : 역전파 학습 \n",
    "    5. optimizer.step() : 기울기 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030bbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
